import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
from sklearn.utils import shuffle
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MultiLabelBinarizer
from scipy.special import softmax

from flask import Flask, request
app = Flask(__name__)


data_path="C:\\Users\\18131\\Desktop\\O1a\\test\\diseases.csv"
df_train = pd.read_csv(data_path)

Disease     = pd.get_dummies(df_train['Disease'],drop_first=True)

Diseases_columns=Disease.columns;

df_train.drop(['Unnamed: 0'],axis=1,inplace=True)

train_columns = df_train.columns

df_train = pd.DataFrame(df_train)

df_train.columns = train_columns

features = df_train.iloc[:,1:].columns.tolist()
target   = df_train.loc[:, 'Disease'].name

X_train = df_train.iloc[:,1:].values

noise = np.random.normal(0, 0.1, X_train.shape)
X_train=X_train+noise

Y_train = Disease.loc[:,:].values


corr=df_train.iloc[:,1:].corr()
corr=corr.to_numpy()
corr=np.maximum(corr,-0.1)
sns.heatmap(corr, annot=True, cmap='coolwarm')


import torch
import torch.nn as nn
from torch.nn import functional as F
from torch.autograd import Variable

criterian=nn.CrossEntropyLoss()
criterian2=nn.MSELoss()

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__();
        self.fc1=nn.Linear(131,512);
        self.fc2=nn.Linear(512,512);
        self.fc3=nn.Linear(512,512);
        self.fc4=nn.Linear(512,41);
        self.dropout=nn.Dropout(0.2);
        #self.sm=nn.Softmax();
    def forward(self,x):
        x=F.relu(self.fc1(x));
        x=self.dropout(x);
        x=F.relu(self.fc2(x));
        x=self.dropout(x);
        x=F.relu(self.fc3(x));
        x=self.dropout(x);
        x=self.fc4(x);
        #x=self.sm(x);
        return x;
model1=Net();
model1.cuda(0)
model1.eval()
print(model1);


def retrain_model():
    optimizer1=torch.optim.SGD(model1.parameters(),lr=0.03);
    batch_size=50;
    n_epochs=50;
    batch_n=len(X_train)//batch_size;
    train_loss=0
    cont=0
    for epoch in range(n_epochs):
        x_all, y_all = shuffle(X_train, Y_train);
        x_train=x_all[50:];
        y_train=y_all[50:];
        X_test=x_all[:50];
        Y_test=y_all[:50];
        for i in range(batch_n):
            start=i*batch_size;
            end=start+batch_size;
            x_tr1=Variable(torch.FloatTensor(x_train[start:end])).cuda(0);
            y_tr1=Variable(torch.FloatTensor(y_train[start:end])).cuda(0);
            x_te1=Variable(torch.FloatTensor(X_test[:])).cuda(0);
            y_te1=Variable(torch.FloatTensor(Y_test[:])).cuda(0);
            
            optimizer1.zero_grad();
            output1=model1(x_tr1);
    
            
            
            loss1=criterian(output1,y_tr1);
            loss1.backward(retain_graph=True);
            optimizer1.step();
            
            
            
            #train_loss += loss.item()*batch_size;
            cont=cont+1
            if cont % 200== 0:
                output2=model1(x_te1);
                loss2=criterian(output2,y_te1);
                values, labels = torch.max(output2, 1)
                values2, labels2 = torch.max(y_te1[:], 1)
                num_right   = np.sum((labels.cpu() == labels2.cpu()).data.numpy())
                print("accuracy ",num_right/50);
retrain_model()


#values,labels=torch.max(output2, 1)
#values2,labels2=torch.max(y_te1, 1)

#output_new = model1(x_tr1);

#values,st=torch.sort(output2,descending=True)

#ans=st[:,:3].cpu().numpy()


#answers=np.full(131,0);
#answers[1:4]=0;
#x_pd=Variable(torch.FloatTensor(answers.reshape((1,131))).cuda(0));
#output=model1(x_pd);


#cc=output.cpu().detach().numpy().reshape(-1)


#values,st=torch.sort(output,descending=True)
#ans=st[:,:3].cpu().numpy().reshape(-1)
#Diseases_columns[ans[0]],softmax(cc)[ans[0]],Diseases_columns[ans[1]],softmax(cc)[ans[1]],Diseases_columns[ans[2]],softmax(cc)[ans[2]]


#softmax(cc)[[ans[0]]]


def session():
    corrarr=np.full(131,0.3);
    answers=np.full(131,0);
    mark=np.full(131,0)
    questionDone=0;
    while true:
        for i in range(20):
            index = np.argpartition(-corrarr, i)[i]
            if corrarr[index]<0 :
                questionDone=1;
                break;
            if mark[index]==1 :
                continue;
            #send(Diseases_columns[index])----
            #read(feel)-----
            answers[index]=feel;
            mark[index]=1;
            corrarr=corrarr+corr[index]*feel;
            break;
        if questionDone==1:
            break
    x_pd=Variable(torch.FloatTensor(answers.reshape((1,131))).cuda(0));
    output=model1(x_pd);
    cc=output.cpu().detach().numpy().reshape(-1)
    values,st=torch.sort(output,descending=True)
    ans=st[:,:3].cpu().numpy().reshape(-1)
    Diseases_columns[ans[0]],softmax(cc)[ans[0]],Diseases_columns[ans[1]],softmax(cc)[ans[1]],Diseases_columns[ans[2]],softmax(cc)[ans[2]]



